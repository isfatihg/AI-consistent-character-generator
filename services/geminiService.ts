import { GoogleGenAI, Modality } from "@google/genai";

const fileToGenerativePart = async (file: File) => {
  const base64EncodedDataPromise = new Promise<string>((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
    reader.readAsDataURL(file);
  });
  return {
    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
  };
};

const urlToGenerativePart = async (url: string) => {
    const response = await fetch(url);
    const blob = await response.blob();
    const base64EncodedDataPromise = new Promise<string>((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
        reader.readAsDataURL(blob);
    });
    return {
        inlineData: { data: await base64EncodedDataPromise, mimeType: blob.type },
    };
};

export const analyzePose = async (poseImageUrl: string): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  const poseImagePart = await urlToGenerativePart(poseImageUrl);

  const prompt = "Analyze the provided image and describe the full-body pose of the character in a concise, descriptive phrase. This description will be used as a prompt to generate another character in the same pose. For example, 'a person standing confidently with hands on hips' or 'a character sitting cross-legged on the floor'. Focus only on the pose itself.";

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash',
    contents: {
      parts: [
        poseImagePart,
        { text: prompt },
      ],
    },
  });

  return response.text;
};


export const generateBackgroundFromText = async (
  userPrompt: string
): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const finalPrompt = `Generate a high-quality, realistic background image of: "${userPrompt}". This image will be used as a scene for a character. The image should be a wide shot and should not contain any prominent characters or people, allowing space for a character to be composited in later.`;

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: [
        { text: finalPrompt },
      ],
    },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }

  throw new Error("No background image was generated by the API.");
};

export const generateBackgroundFromImage = async (
  styleImage: File,
  userPrompt: string
): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  const styleImagePart = await fileToGenerativePart(styleImage);

  const finalPrompt = `Generate a new, high-quality background image. Use the provided image as a strong style, theme, and color palette reference. The new background should depict the following scene: "${userPrompt}". The final image should be a new creation inspired by the reference image, not an edit of it. It should not contain prominent characters.`;

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: [
        styleImagePart,
        { text: finalPrompt },
      ],
    },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }
  
  throw new Error("No background image was generated from the style image.");
}


export const generateCharacterFromText = async (
  userPrompt: string
): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const finalPrompt = `Generate a full-body character portrait based on the following description: "${userPrompt}". The character should be centered against a simple, neutral background.`;

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: [
        { text: finalPrompt },
      ],
    },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }

  throw new Error("No image was generated by the API.");
};


export const editImage = async (
  sourceImage: File | string,
  userPrompt: string,
  apparelImage: File | null
): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const imagePart = typeof sourceImage === 'string'
    ? await urlToGenerativePart(sourceImage)
    : await fileToGenerativePart(sourceImage as File);

  const parts = [imagePart];
  let finalPrompt = `Your task is to edit an image based on user instructions.
1. Analyze the provided character image.
2. Apply the following user instruction: "${userPrompt}"`;
  
  if (apparelImage) {
    const apparelPart = await fileToGenerativePart(apparelImage);
    parts.push(apparelPart);
    finalPrompt += `\n3. Additionally, dress the character in the outfit shown in the second provided image (the apparel image).`;
  }

  finalPrompt += `\n4. The final image should be a modified version of the original image, reflecting the user's request. Ensure the core subject and style of the original image are preserved unless the instruction explicitly asks to change them.`

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: [...parts, { text: finalPrompt }],
    },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }

  throw new Error("No image was generated by the API.");
};


export const generateImageFromPose = async (
  characterImage: File | string,
  poseImageUrl: string,
  poseDescription: string,
  userPrompt: string,
  backgroundImage: File | null,
  apparelImage: File | null
): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const characterPart = typeof characterImage === 'string' 
    ? await urlToGenerativePart(characterImage)
    : await fileToGenerativePart(characterImage as File);
    
  const posePart = await urlToGenerativePart(poseImageUrl);

  const parts = [characterPart, posePart];
  let promptParts: string[] = [];
  let stepCounter = 1;

  promptParts.push(`${stepCounter++}. Analyze the character in the first image. Pay close attention to all details: hairstyle, colors, facial features, and overall style.`);
  promptParts.push(`${stepCounter++}. Analyze the pose in the second image. This is the target pose for the character. The pose is described as: "${poseDescription}".`);
  
  if (apparelImage) {
    const apparelPart = await fileToGenerativePart(apparelImage);
    parts.push(apparelPart);
    promptParts.push(`${stepCounter++}. Analyze the apparel in the third image. This is the new outfit for the character.`);
  }

  if (backgroundImage) {
    const backgroundPart = await fileToGenerativePart(backgroundImage);
    parts.push(backgroundPart);
    const bgImageNumber = apparelImage ? 'fourth' : 'third';
    promptParts.push(`${stepCounter++}. Analyze the background in the ${bgImageNumber} image. This is the new environment.`);
    
    let redrawInstruction = `Redraw the character from the first image in the exact pose from the second image.`;
    if (apparelImage) {
        redrawInstruction = `Redraw the character from the first image, dressed in the apparel from the third image, in the exact pose from the second image.`;
    }
    promptParts.push(`${stepCounter++}. ${redrawInstruction}`);
    promptParts.push(`${stepCounter++}. Place this newly posed and dressed character convincingly into the background from the ${bgImageNumber} image. Ensure lighting and shadows on the character match the background.`);

  } else {
    let redrawInstruction = `Redraw the character from the first image in the exact pose shown in the second image.`;
    if (apparelImage) {
        redrawInstruction = `Redraw the character from the first image, dressed in the apparel from the third image, in the exact pose from the second image.`
    }
    promptParts.push(`${stepCounter++}. ${redrawInstruction}`);
    promptParts.push(`${stepCounter++}. The final image should ONLY contain the character in the new pose. Maintain the background from the original character image unless specified otherwise. Do not include the pose reference image in the output.`);
  }
  
  promptParts.push(`If user instructions are provided, apply them. Instructions: "${userPrompt || 'No additional instructions.'}"`);

  const finalPrompt = `Your task is to generate a consistent character.\n${promptParts.join('\n')}`;

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: [...parts, { text: finalPrompt }],
    },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }

  throw new Error("No image was generated by the API.");
};